{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J0OZuBm09LrW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9GVRs4U8525",
        "outputId": "06baf961-f228-4bd6-9fa0-87e337dc4532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.22.4)\n",
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari]) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install cmake 'gym[atari]' scipy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym # openAi gym\n",
        "import datetime\n",
        "from time import sleep\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "import sys\n"
      ],
      "metadata": {
        "id": "eUqIuZG488DX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v3\").env\n",
        "\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDHaG5Nj9ADm",
        "outputId": "2985be8c-70be-487c-c4f3-7ada1a96ef26"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's first do some random steps in the game so you see how the game looks like\n",
        "\n",
        "rew_tot=0\n",
        "obs= env.reset()\n",
        "env.render()\n",
        "for _ in range(6):\n",
        "    action = env.action_space.sample() #take step using random action from possible actions (actio_space)\n",
        "    obs, rew, done, info = env.step(action) \n",
        "    rew_tot = rew_tot + rew\n",
        "    env.render()\n",
        "#Print the reward of these random action\n",
        "print(\"Reward: %r\" % rew_tot)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfK31DC09E7u",
        "outputId": "4f4cfcec-2bdb-41fe-86d7-85f8b4a9bc2c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| :\u001b[43m \u001b[0m|\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y|\u001b[43m \u001b[0m: |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| |\u001b[43m \u001b[0m: | : |\n",
            "|Y| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "  (North)\n",
            "Reward: -33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.observation_space)\n",
        "print()\n",
        "env.s=49 # some random number, you might recognize it\n",
        "env.render()\n",
        "env.s = 450 # and some other\n",
        "env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-63MCfb9E0G",
        "outputId": "c8c01ce3-d544-4c55-e4ca-9f9cc6d04807"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(500)\n",
            "\n",
            "+---------+\n",
            "|R: |\u001b[43m \u001b[0m: :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35m\u001b[34;1mY\u001b[0m\u001b[0m| :\u001b[43m \u001b[0m|B: |\n",
            "+---------+\n",
            "  (North)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Brute force approach"
      ],
      "metadata": {
        "id": "J0OZuBm09LrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_space.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EbiM94J9EuG",
        "outputId": "a89de862-7c3a-4578-cfc2-886115983165"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Brute_force (env):\n",
        "  env = gym.make(\"Taxi-v3\").env\n",
        "  #reset environment to random state\n",
        "  env.reset() \n",
        "  print(\"Action Space {}\".format(env.action_space))\n",
        "  print(\"State Space {}\".format(env.observation_space))\n",
        "  env.render()\n",
        "  #BruteForce Approach\n",
        "  env.s=152\n",
        "  epochs = 0\n",
        "  penalties, reward = 0, 0\n",
        "  global frames\n",
        "  frames = [] \n",
        "  done = False\n",
        "  while not done:\n",
        "    action = env.action_space.sample()\n",
        "    state, reward, done, info = env.step(action)\n",
        "\n",
        "    if reward == -10:\n",
        "        penalties += 1\n",
        "    \n",
        "    # Put each rendered frame into dict for animation\n",
        "    frames.append({\n",
        "        'frame': env.render(mode='ansi'),\n",
        "        'state': state,\n",
        "        'action': action,\n",
        "        'reward': reward\n",
        "        }\n",
        "    )\n",
        "\n",
        "    epochs += 1     \n",
        "  print(\"Timesteps taken: {}\".format(epochs)) \n",
        "  print(\"Penalties incurred: {}\".format(penalties))"
      ],
      "metadata": {
        "id": "mkB7Kw6d9EmO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Brute_force(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAHXpRwW9EaY",
        "outputId": "925f202e-52b7-4d8e-97db-57e672781060"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action Space Discrete(6)\n",
            "State Space Discrete(500)\n",
            "+---------+\n",
            "|\u001b[34;1mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[43m \u001b[0m: |\n",
            "|\u001b[35mY\u001b[0m| : |B: |\n",
            "+---------+\n",
            "\n",
            "Timesteps taken: 1096\n",
            "Penalties incurred: 357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Q-learning algorithm"
      ],
      "metadata": {
        "id": "mAvsiMDU9UEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def qLearning(env,l=[0.1,0.95,0.1]):\n",
        "  print(\"\\n----------------------------------------------------------------------\")\n",
        "  %%time\n",
        "  env = gym.make(\"Taxi-v3\").env\n",
        "  # Initialize the q table\n",
        "  global Q\n",
        "  Q = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "  episodes=[]\n",
        "  print(\"Hyper Parameters \",l)\n",
        "  # For plotting metrics\n",
        "  all_epochs = []\n",
        "  all_penalties = []\n",
        "\n",
        "  for i in range(1, 10001):\n",
        "    state = env.reset()\n",
        "\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < l[2]:\n",
        "            action = env.action_space.sample() # Explore action space\n",
        "        else:\n",
        "            action = np.argmax(Q[state]) # Exploit learned values\n",
        "\n",
        "        next_state, reward, done, info = env.step(action) \n",
        "        old_value = Q[state, action]\n",
        "        next_max = np.max(Q[next_state])\n",
        "    \n",
        "        new_value = (1 - l[0]) * old_value + l[0] * (reward + l[1] * next_max)\n",
        "        Q[state, action] = new_value\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "    if i % 1000 == 0:\n",
        "        #clear_output(wait=True)\n",
        "        l[0] -=.005\n",
        "        l[2] -=.001\n",
        "  \n",
        "  print(\"Alpha\",l[0])\n",
        "  print(\"Gamma = \",l[1])\n",
        "  print(\"Epsilon =\",l[2])\n",
        "  print(\"epochs\",epochs)\n",
        "  print(\"Training finished.\\n\")\n",
        "  return Q"
      ],
      "metadata": {
        "id": "Q-fkV8D69U43"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = qLearning(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2rPL66h9U_X",
        "outputId": "c0259134-f39c-4c7a-e38d-11ce43ff95ce"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 9.54 µs\n",
            "Hyper Parameters  [0.1, 0.95, 0.1]\n",
            "Alpha 0.04999999999999998\n",
            "Gamma =  0.95\n",
            "Epsilon = 0.09\n",
            "epochs 13\n",
            "Training finished.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yBLA70q9ERG",
        "outputId": "0a79e5f5-d915-4a0f-9b72-ef8ff7e6b99d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
              "         0.        ],\n",
              "       [-0.0252097 ,  1.90059144, -1.13649441,  2.28821047,  5.20997639,\n",
              "        -5.31311473],\n",
              "       [ 4.70062583,  6.01723947,  2.50203205,  5.71705632, 10.9512375 ,\n",
              "        -1.9288565 ],\n",
              "       ...,\n",
              "       [-0.97779739,  7.53687   , -0.92499083, -0.93464908, -1.98844096,\n",
              "        -2.81580834],\n",
              "       [-2.77973455, -2.76036234, -2.56484467,  3.71021833, -4.26716432,\n",
              "        -2.92713834],\n",
              "       [-0.1995    , -0.2089525 ,  0.98662691, 17.55495355, -0.52302096,\n",
              "        -1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how the algorithm solves the frozen-lakes game\n",
        "\n",
        "rew_tot=0.\n",
        "obs= env.reset()\n",
        "done=False\n",
        "while done != True: \n",
        "    action = np.argmax(Q[obs])\n",
        "    obs, rew, done, info = env.step(action) #take step using selected action\n",
        "    rew_tot += rew\n",
        "    env.render()\n",
        "\n",
        "print(\"Reward:\", rew_tot) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfdaW05_9dsP",
        "outputId": "007d1c12-de94-494c-b660-7d3622edd3d6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : :\u001b[43m \u001b[0m|\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | :\u001b[43m \u001b[0m: |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (West)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : :\u001b[43m \u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[43m \u001b[0m: |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1m\u001b[43mB\u001b[0m\u001b[0m: |\n",
            "+---------+\n",
            "  (South)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[42mB\u001b[0m: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : |\u001b[42m_\u001b[0m: |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : :\u001b[42m_\u001b[0m|\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : | : :\u001b[42m_\u001b[0m|\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "Reward: 9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluate the agent"
      ],
      "metadata": {
        "id": "cP3fvq_O9gb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.lib.function_base import append\n",
        "\"\"\"Evaluate agent's performance after Q-learning\"\"\"\n",
        "def Evaluate_agent (Q):\n",
        "  total_epochs, total_penalties = 0, 0\n",
        "  totaltimesteps=[]\n",
        "  episodes = 100\n",
        "\n",
        "  for _ in range(episodes):\n",
        "      state = env.reset()\n",
        "      epochs, penalties, reward = 0, 0, 0\n",
        "      \n",
        "      done = False\n",
        "      \n",
        "      while not done:\n",
        "          action = np.argmax(Q[state])\n",
        "          state, reward, done, info = env.step(action)\n",
        "\n",
        "          if reward == -10:\n",
        "              penalties += 1\n",
        "\n",
        "          epochs += 1\n",
        "\n",
        "      total_penalties += penalties\n",
        "      total_epochs += epochs\n",
        "     \n",
        " \n",
        "  print(f\"\\nResults after {episodes} episodes:\")\n",
        "  print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "  print(f\"Average penalties per episode: {total_penalties / episodes}\")\n",
        "  totaltimesteps.append(total_epochs/episodes)\n",
        "\n",
        "  return totaltimesteps\n",
        "  "
      ],
      "metadata": {
        "id": "zRmGORKs9dnf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Evaluate_agent(Q))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aZmzUBF9dhv",
        "outputId": "9d8687d7-f998-4875-a1a8-ed1e50a259fc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.03\n",
            "Average penalties per episode: 0.0\n",
            "[13.03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Grid search"
      ],
      "metadata": {
        "id": "lFuuXBOy9miW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters that used in your Grid Search\n",
        "# with the list of values that you wish to try out\n",
        "\n",
        "gamma = [.5,.6,.7]\n",
        "alpha = [.5,.6,.7]\n",
        "Epsilon  = [.5,.6,.7]\n",
        "\n",
        "lists=[alpha,gamma,Epsilon]\n",
        "\n"
      ],
      "metadata": {
        "id": "JMJq6ECM9pJu"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lists"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srdgR5jB9psm",
        "outputId": "b54ba846-6fb3-42dc-afe7-f6b4f20fa259"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.5, 0.6, 0.7], [0.5, 0.6, 0.7], [0.5, 0.6, 0.7]]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Averge_time=[]\n",
        "print (\"All lists: \" + str(lists))\n",
        "the_result = list(itertools.product(*lists)) \n",
        "print (\"All permutations : \" +  str(the_result))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Br-e02c95OO",
        "outputId": "977b6a8f-c2eb-4f2d-bb40-64e0d9a5b53c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All lists: [[0.5, 0.6, 0.7], [0.5, 0.6, 0.7], [0.5, 0.6, 0.7]]\n",
            "All permutations : [(0.5, 0.5, 0.5), (0.5, 0.5, 0.6), (0.5, 0.5, 0.7), (0.5, 0.6, 0.5), (0.5, 0.6, 0.6), (0.5, 0.6, 0.7), (0.5, 0.7, 0.5), (0.5, 0.7, 0.6), (0.5, 0.7, 0.7), (0.6, 0.5, 0.5), (0.6, 0.5, 0.6), (0.6, 0.5, 0.7), (0.6, 0.6, 0.5), (0.6, 0.6, 0.6), (0.6, 0.6, 0.7), (0.6, 0.7, 0.5), (0.6, 0.7, 0.6), (0.6, 0.7, 0.7), (0.7, 0.5, 0.5), (0.7, 0.5, 0.6), (0.7, 0.5, 0.7), (0.7, 0.6, 0.5), (0.7, 0.6, 0.6), (0.7, 0.6, 0.7), (0.7, 0.7, 0.5), (0.7, 0.7, 0.6), (0.7, 0.7, 0.7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps=[]\n",
        "for i in range(27):\n",
        "  Q_1=qLearning(env,list(the_result[i]))\n",
        "  print(\"\\n\",Q_1,\"\\n\")\n",
        "  avg_timesteps=Evaluate_agent(Q_1)\n",
        "  parameter_metric_dict={\"alpha\":the_result[i][0],\"gamma\":the_result[i][1],\"Epsilon\":the_result[i][2],\"avg_timesteps\":avg_timesteps}\n",
        "  steps.append(parameter_metric_dict)\n",
        "listoftimesteps=[]\n",
        "for i in steps:\n",
        "  avg_timesteps=i.get(\"avg_timesteps\")\n",
        "  listoftimesteps.append(avg_timesteps)\n",
        "\n",
        "print(\"\\nThe minimum time step is  \",steps[listoftimesteps.index(min(listoftimesteps))])  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTEM-iQk9pke",
        "outputId": "32b06b8b-2352-461e-ff4e-07df9ec6c1c6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 7.39 µs\n",
            "Hyper Parameters  [0.5, 0.5, 0.5]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.49\n",
            "epochs 46\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703102  -1.91406279  -1.95703094  -1.9140625  -10.95703099\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.18\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.5, 0.5, 0.6]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.59\n",
            "epochs 40\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.18\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.5, 0.5, 0.7]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.69\n",
            "epochs 44\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.03\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n",
            "Hyper Parameters  [0.5, 0.6, 0.5]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.49\n",
            "epochs 23\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.75040586   0.416       -0.75041785  -1.4502403   -9.75040343\n",
            "   -9.75037187]\n",
            " [ -2.27325191  -2.12210158  -2.27325188  -2.1220864  -11.2732514\n",
            "  -11.27325037]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.55\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.5, 0.6, 0.6]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.59\n",
            "epochs 57\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.21\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.5, 0.6, 0.7]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.69\n",
            "epochs 29\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.96\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.5, 0.7, 0.5]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.49\n",
            "epochs 38\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.58829694   2.269        0.58829926  -0.58819543  -8.411704\n",
            "   -8.41171175]\n",
            " [ -2.39174918  -1.98821377  -2.39188026  -1.9882131  -11.39174601\n",
            "  -11.3917481 ]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.26\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.25 µs\n",
            "Hyper Parameters  [0.5, 0.7, 0.6]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.59\n",
            "epochs 25\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.41170001\n",
            "   -8.41170003]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174918]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.32\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.2 µs\n",
            "Hyper Parameters  [0.5, 0.7, 0.7]\n",
            "Alpha 0.44999999999999996\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.69\n",
            "epochs 18\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.4117\n",
            "   -8.4117    ]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.05\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.25 µs\n",
            "Hyper Parameters  [0.6, 0.5, 0.5]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.49\n",
            "epochs 34\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.31250016  -0.625       -1.31573989  -1.65625    -10.31249879\n",
            "  -10.31253721]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703124\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.19\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.6, 0.5, 0.6]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.59\n",
            "epochs 44\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.07\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.6, 0.5, 0.7]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.69\n",
            "epochs 55\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.08\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.6, 0.6, 0.5]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.49\n",
            "epochs 18\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.75040047   0.416       -0.75040008  -1.45024003  -9.75040015\n",
            "   -9.75040003]\n",
            " [ -2.27325184  -2.12208642  -2.27325185  -2.1220864  -11.27325146\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.45\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.6, 0.6, 0.6]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.59\n",
            "epochs 23\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.67\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.6, 0.6, 0.7]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.69\n",
            "epochs 85\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.08\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.6, 0.7, 0.5]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.49\n",
            "epochs 23\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.58829996   2.269        0.58829991  -0.58819604  -8.41169962\n",
            "   -8.41169907]\n",
            " [ -2.39178469  -1.9882131   -2.39174918  -1.98821315 -11.39174917\n",
            "  -11.39173476]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.15\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.6, 0.7, 0.6]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.59\n",
            "epochs 40\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.4117\n",
            "   -8.4117    ]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.11\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.68 µs\n",
            "Hyper Parameters  [0.6, 0.7, 0.7]\n",
            "Alpha 0.5499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.69\n",
            "epochs 70\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.4117\n",
            "   -8.4117    ]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.95\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 4.53 µs\n",
            "Hyper Parameters  [0.7, 0.5, 0.5]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.49\n",
            "epochs 20\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.31250001\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.13\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.53 µs\n",
            "Hyper Parameters  [0.7, 0.5, 0.6]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.59\n",
            "epochs 28\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.96\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.7, 0.5, 0.7]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.5\n",
            "Epsilon = 0.69\n",
            "epochs 27\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.98925781  -1.97851562  -1.98925781  -1.97851562  -1.95703125\n",
            "  -10.97851562]\n",
            " [ -1.828125    -1.65625     -1.828125    -1.65625     -1.3125\n",
            "  -10.65625   ]\n",
            " ...\n",
            " [ -1.3125      -0.625       -1.3125      -1.65625    -10.3125\n",
            "  -10.3125    ]\n",
            " [ -1.95703125  -1.9140625   -1.95703125  -1.9140625  -10.95703125\n",
            "  -10.95703125]\n",
            " [  3.5          0.75         3.5          9.          -5.5\n",
            "   -5.5       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.38\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
            "Wall time: 4.53 µs\n",
            "Hyper Parameters  [0.7, 0.6, 0.5]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.49\n",
            "epochs 25\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27324851\n",
            "  -11.27325178]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.75\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.53 µs\n",
            "Hyper Parameters  [0.7, 0.6, 0.6]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.59\n",
            "epochs 26\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.26\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.7, 0.6, 0.7]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.6\n",
            "Epsilon = 0.69\n",
            "epochs 62\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.41837066  -2.3639511   -2.41837066  -2.3639511   -2.27325184\n",
            "  -11.3639511 ]\n",
            " [ -1.870144    -1.45024     -1.870144    -1.45024     -0.7504\n",
            "  -10.45024   ]\n",
            " ...\n",
            " [ -0.7504       0.416       -0.7504      -1.45024     -9.7504\n",
            "   -9.7504    ]\n",
            " [ -2.27325184  -2.1220864   -2.27325184  -2.1220864  -11.27325184\n",
            "  -11.27325184]\n",
            " [  5.6          2.36         5.6         11.          -3.4\n",
            "   -3.4       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.33\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.7, 0.7, 0.5]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.49\n",
            "epochs 30\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.58829996   2.269        0.5883      -0.58819086  -8.41170002\n",
            "   -8.41170056]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174918\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.08\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.77 µs\n",
            "Hyper Parameters  [0.7, 0.7, 0.6]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.59\n",
            "epochs 24\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.4117\n",
            "   -8.4117    ]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 13.6\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.01 µs\n",
            "Hyper Parameters  [0.7, 0.7, 0.7]\n",
            "Alpha 0.6499999999999999\n",
            "Gamma =  0.7\n",
            "Epsilon = 0.69\n",
            "epochs 64\n",
            "Training finished.\n",
            "\n",
            "\n",
            " [[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -2.87195709  -2.67422442  -2.87195709  -2.67422442  -2.39174917\n",
            "  -11.67422442]\n",
            " [ -1.411733    -0.58819     -1.411733    -0.58819      0.5883\n",
            "   -9.58819   ]\n",
            " ...\n",
            " [  0.5883       2.269        0.5883      -0.58819     -8.4117\n",
            "   -8.4117    ]\n",
            " [ -2.39174917  -1.9882131   -2.39174917  -1.9882131  -11.39174917\n",
            "  -11.39174917]\n",
            " [  8.1          4.67         8.1         13.          -0.9\n",
            "   -0.9       ]] \n",
            "\n",
            "\n",
            "Results after 100 episodes:\n",
            "Average timesteps per episode: 12.85\n",
            "Average penalties per episode: 0.0\n",
            "\n",
            "The minimum time step is   {'alpha': 0.6, 'gamma': 0.6, 'Epsilon': 0.6, 'avg_timesteps': [12.67]}\n"
          ]
        }
      ]
    }
  ]
}